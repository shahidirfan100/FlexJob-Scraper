# FlexJobs Scraper

This Apify actor scrapes job listings from FlexJobs using HTTP requests and Cheerio for parsing. It is designed to be fast, lightweight, and highly stealthy, avoiding detection and blocking with advanced anti-bot techniques.

## Features

- ðŸš€ **Fast & Lightweight**: Uses `got-scraping` and Cheerio instead of headless browsers
- ðŸ¥· **Advanced Stealth**: Latest browser fingerprinting (Chrome 131), client hints, and human-like behavior
- ðŸ”„ **Robust Error Handling**: Exponential backoff, aggressive session rotation, and 403 error recovery
- ðŸŽ¯ **Smart Company Extraction**: Multiple fallback strategies including JSON-LD, HTML selectors, and description parsing
- ðŸ“Š **Comprehensive Data**: Extracts title, company, location, salary, remote level, job type, and full descriptions
- ðŸ”— **Automatic Pagination**: Handles pagination to collect multiple pages of results
- ðŸ’¾ **Apify Integration**: Saves results to Apify dataset with full metadata

## ðŸŽ“ Stealth Best Practices Implemented

âœ… **Latest browser versions** (Oct 2025 - Chrome 131)  
âœ… **Complete client hint headers** (sec-ch-ua-*)  
âœ… **Version consistency** (UA matches all headers)  
âœ… **Random timing patterns** with network latency  
âœ… **Human-like delays** (reading/browsing simulation)  
âœ… **Network latency simulation** (DNS + TCP handshake)  
âœ… **Aggressive session rotation** (max 8 uses per session)  
âœ… **Exponential backoff with jitter** for retries  
âœ… **Lower concurrency** (2 concurrent requests default)  
âœ… **Natural request pacing** between enqueues  
âœ… **Realistic referer chains** tracked across navigation  
âœ… **No bot signatures** (no DNT header, proper Sec-Fetch-*)

## Input

The actor accepts the following input fields:

- `startUrls`: Array of FlexJobs category URLs to start crawling from (default: remote jobs homepage)
- `results_wanted`: Maximum number of jobs to scrape (default: 100)
- `maxPagesPerList`: Maximum number of pages to visit per category (default: 25)
- `maxConcurrency`: Maximum concurrent requests - lower is more stealthy (default: 2)
- `proxyConfiguration`: Apify Proxy configuration (recommended: Residential proxies)
- `cookies`: Optional array of cookies for authentication
- `debugMode`: Enable debug logging and save problematic pages

## Output

The actor outputs a dataset of job listings with the following fields:

- `source`: Always "flexjobs"
- `url`: The URL of the job posting
- `title`: The job title
- `company`: Company name (extracted from multiple sources)
- `location`: Job location or "Remote"
- `remote_level`: Type of remote work (e.g., "100% Remote")
- `job_type`: Employment type (Full-time, Part-time, Contract, etc.)
- `schedule`: Work schedule
- `salary`: Salary information if available
- `benefits`: Benefits information
- `career_level`: Seniority level
- `description`: Job description HTML
- `text`: Job description plain text
- `posted_date`: When the job was posted
- `valid_through`: Job expiration date
- `scraped_at`: ISO timestamp of when data was collected

## Company Name Extraction Strategy

The actor uses multiple fallback strategies to extract company names:

1. **JSON-LD structured data** (`hiringOrganization`)
2. **HTML metadata** (job listing metadata sections)
3. **CSS selectors** (company links, data attributes)
4. **Description parsing** (regex patterns like "Company: XYZ", "About XYZ")
5. **Page metadata** (OpenGraph, Twitter cards)

This multi-layered approach ensures maximum company name capture even when behind login walls.

## Proxy Recommendations

For best results avoiding 403 errors:
- Use **Residential proxies** for maximum stealth
- Enable **session persistence** (automatically handled)
- The actor rotates sessions aggressively to avoid detection

## Notes

- The actor crawls public category pages and does not require login
- FlexJobs keyword search is restricted for anonymous users, so the actor starts from category URLs
- All selectors and pagination logic have been preserved and tested
- Compatible with Apify platform QA tests